{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Churn Modelling </center>\n",
    "# <center> Neural Network Project</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We need to import some libraries that we need further in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1663df30c3d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <center> Step one: Preparing the Data</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1.1:<br>\n",
    "We Read Dataset form csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Class/Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Class/Exited  \n",
       "0        101348.88             1  \n",
       "1        112542.58             0  \n",
       "2        113931.57             1  \n",
       "3         93826.63             0  \n",
       "4         79084.10             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(os.path.join(os.getcwd(),\"churn-modelling.csv\"))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1.2:<br>\n",
    "We must encode the features that isn't int or float like Gender & Geography<br>\n",
    "So we convert  Gender Man to 1 & Gender Woman to 0(zero)<br>\n",
    "And because Geography is 3 type so we can't convert to 0,1,2 because the relationship between 0 and 2 is just like the <br> \n",
    "rellationship between 0 and 1<br>\n",
    "Example : average 0 and 2 is 1 but average Spain and Germany isn't France :)<br>\n",
    "So we convert it to one_hot vector <br>\n",
    "We deleted  RowNumber, CustomerId,Surname,Geography Because we didn't need them now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>Class/Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       0   42       2       0.00              1          1   \n",
       "1             608       0   41       1   83807.86              1          0   \n",
       "2             502       0   42       8  159660.80              3          1   \n",
       "3             699       0   39       1       0.00              2          0   \n",
       "4             850       0   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       1   39       5       0.00              2          1   \n",
       "9996          516       1   35      10   57369.61              1          1   \n",
       "9997          709       0   36       7       0.00              1          0   \n",
       "9998          772       1   42       3   75075.31              2          1   \n",
       "9999          792       0   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  country_France  country_Germany  \\\n",
       "0                  1        101348.88               1                0   \n",
       "1                  1        112542.58               0                0   \n",
       "2                  0        113931.57               1                0   \n",
       "3                  0         93826.63               1                0   \n",
       "4                  1         79084.10               0                0   \n",
       "...              ...              ...             ...              ...   \n",
       "9995               0         96270.64               1                0   \n",
       "9996               1        101699.77               1                0   \n",
       "9997               1         42085.58               1                0   \n",
       "9998               0         92888.52               0                1   \n",
       "9999               0         38190.78               1                0   \n",
       "\n",
       "      country_Spain  Class/Exited  \n",
       "0                 0             1  \n",
       "1                 1             0  \n",
       "2                 0             1  \n",
       "3                 0             0  \n",
       "4                 1             0  \n",
       "...             ...           ...  \n",
       "9995              0             0  \n",
       "9996              0             0  \n",
       "9997              0             1  \n",
       "9998              0             1  \n",
       "9999              0             0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['Geography'], prefix='country')],axis=1)\n",
    "df['Gender'] = pd.Categorical(df['Gender'])\n",
    "df['Gender'] = df.Gender.cat.codes\n",
    "df = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\",'Geography'], axis=1)\n",
    "df = df[['CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','country_France','country_Germany','country_Spain','Class/Exited']]\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[[-0.32622142 -1.09598752  0.29351742 ...  0.99720391 -0.57873591\n",
      "  -0.57380915]\n",
      " [-0.44003595 -1.09598752  0.19816383 ... -1.00280393 -0.57873591\n",
      "   1.74273971]\n",
      " [-1.53679418 -1.09598752  0.29351742 ...  0.99720391 -0.57873591\n",
      "  -0.57380915]\n",
      " ...\n",
      " [ 0.60498839 -1.09598752 -0.27860412 ...  0.99720391 -0.57873591\n",
      "  -0.57380915]\n",
      " [ 1.25683526  0.91241915  0.29351742 ... -1.00280393  1.72790383\n",
      "  -0.57380915]\n",
      " [ 1.46377078 -1.09598752 -1.04143285 ...  0.99720391 -0.57873591\n",
      "  -0.57380915]]\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>Class/Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.246488</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.066419</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.391939</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>1.724464</td>\n",
       "      <td>-0.306379</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.604988</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.278604</td>\n",
       "      <td>0.687130</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.008643</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.256835</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-0.695982</td>\n",
       "      <td>-0.022608</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.463771</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-1.041433</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>0.859965</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-1.076370</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore    Gender       Age    Tenure   Balance  NumOfProducts  \\\n",
       "0       -0.326221 -1.095988  0.293517 -1.041760 -1.225848      -0.911583   \n",
       "1       -0.440036 -1.095988  0.198164 -1.387538  0.117350      -0.911583   \n",
       "2       -1.536794 -1.095988  0.293517  1.032908  1.333053       2.527057   \n",
       "3        0.501521 -1.095988  0.007457 -1.387538 -1.225848       0.807737   \n",
       "4        2.063884 -1.095988  0.388871 -1.041760  0.785728      -0.911583   \n",
       "...           ...       ...       ...       ...       ...            ...   \n",
       "9995     1.246488  0.912419  0.007457 -0.004426 -1.225848       0.807737   \n",
       "9996    -1.391939  0.912419 -0.373958  1.724464 -0.306379      -0.911583   \n",
       "9997     0.604988 -1.095988 -0.278604  0.687130 -1.225848      -0.911583   \n",
       "9998     1.256835  0.912419  0.293517 -0.695982 -0.022608       0.807737   \n",
       "9999     1.463771 -1.095988 -1.041433 -0.350204  0.859965      -0.911583   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  country_France  \\\n",
       "0      0.646092        0.970243         0.021886        0.997204   \n",
       "1     -1.547768        0.970243         0.216534       -1.002804   \n",
       "2      0.646092       -1.030670         0.240687        0.997204   \n",
       "3     -1.547768       -1.030670        -0.108918        0.997204   \n",
       "4      0.646092        0.970243        -0.365276       -1.002804   \n",
       "...         ...             ...              ...             ...   \n",
       "9995   0.646092       -1.030670        -0.066419        0.997204   \n",
       "9996   0.646092        0.970243         0.027988        0.997204   \n",
       "9997  -1.547768        0.970243        -1.008643        0.997204   \n",
       "9998   0.646092       -1.030670        -0.125231       -1.002804   \n",
       "9999   0.646092       -1.030670        -1.076370        0.997204   \n",
       "\n",
       "      country_Germany  country_Spain  Class/Exited  \n",
       "0           -0.578736      -0.573809             1  \n",
       "1           -0.578736       1.742740             0  \n",
       "2           -0.578736      -0.573809             1  \n",
       "3           -0.578736      -0.573809             0  \n",
       "4           -0.578736       1.742740             0  \n",
       "...               ...            ...           ...  \n",
       "9995        -0.578736      -0.573809             0  \n",
       "9996        -0.578736      -0.573809             0  \n",
       "9997        -0.578736      -0.573809             1  \n",
       "9998         1.727904      -0.573809             1  \n",
       "9999        -0.578736      -0.573809             0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df1=df.copy()\n",
    "df1=df1.drop(['Class/Exited'], axis=1)\n",
    "df1=preprocessing.scale(df1)\n",
    "df1\n",
    "\n",
    "print(df1)\n",
    "print(len(df1))\n",
    "# df.head()\n",
    "df2=pd.DataFrame(data=df1[0:,0:],index=range(10000),columns=['CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','country_France','country_Germany','country_Spain'])\n",
    "df2['Class/Exited']=df['Class/Exited']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>Class/Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.246488</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.066419</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.391939</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>1.724464</td>\n",
       "      <td>-0.306379</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.604988</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.278604</td>\n",
       "      <td>0.687130</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.008643</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.256835</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-0.695982</td>\n",
       "      <td>-0.022608</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.463771</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-1.041433</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>0.859965</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-1.076370</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore    Gender       Age    Tenure   Balance  NumOfProducts  \\\n",
       "0       -0.326221 -1.095988  0.293517 -1.041760 -1.225848      -0.911583   \n",
       "1       -0.440036 -1.095988  0.198164 -1.387538  0.117350      -0.911583   \n",
       "2       -1.536794 -1.095988  0.293517  1.032908  1.333053       2.527057   \n",
       "3        0.501521 -1.095988  0.007457 -1.387538 -1.225848       0.807737   \n",
       "4        2.063884 -1.095988  0.388871 -1.041760  0.785728      -0.911583   \n",
       "...           ...       ...       ...       ...       ...            ...   \n",
       "9995     1.246488  0.912419  0.007457 -0.004426 -1.225848       0.807737   \n",
       "9996    -1.391939  0.912419 -0.373958  1.724464 -0.306379      -0.911583   \n",
       "9997     0.604988 -1.095988 -0.278604  0.687130 -1.225848      -0.911583   \n",
       "9998     1.256835  0.912419  0.293517 -0.695982 -0.022608       0.807737   \n",
       "9999     1.463771 -1.095988 -1.041433 -0.350204  0.859965      -0.911583   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  country_France  \\\n",
       "0      0.646092        0.970243         0.021886        0.997204   \n",
       "1     -1.547768        0.970243         0.216534       -1.002804   \n",
       "2      0.646092       -1.030670         0.240687        0.997204   \n",
       "3     -1.547768       -1.030670        -0.108918        0.997204   \n",
       "4      0.646092        0.970243        -0.365276       -1.002804   \n",
       "...         ...             ...              ...             ...   \n",
       "9995   0.646092       -1.030670        -0.066419        0.997204   \n",
       "9996   0.646092        0.970243         0.027988        0.997204   \n",
       "9997  -1.547768        0.970243        -1.008643        0.997204   \n",
       "9998   0.646092       -1.030670        -0.125231       -1.002804   \n",
       "9999   0.646092       -1.030670        -1.076370        0.997204   \n",
       "\n",
       "      country_Germany  country_Spain  Class/Exited  \n",
       "0           -0.578736      -0.573809             1  \n",
       "1           -0.578736       1.742740             0  \n",
       "2           -0.578736      -0.573809             1  \n",
       "3           -0.578736      -0.573809             0  \n",
       "4           -0.578736       1.742740             0  \n",
       "...               ...            ...           ...  \n",
       "9995        -0.578736      -0.573809             0  \n",
       "9996        -0.578736      -0.573809             0  \n",
       "9997        -0.578736      -0.573809             1  \n",
       "9998         1.727904      -0.573809             1  \n",
       "9999        -0.578736      -0.573809             0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy=df.copy()\n",
    "df=df2.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see some graphs of our data and its distribution and relativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df[['IsActiveMember','EstimatedSalary','country_France','country_Germany','country_Spain','Class/Exited']],markers=[\"o\", \"x\"], hue='Class/Exited');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_mat = df.corr() \n",
    "fig, ax = plt.subplots(figsize=(20, 12)) \n",
    "sns.heatmap(corr_mat, vmax=1, square=True, ax=ax);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Shuffle our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>Class/Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>1.287876</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>1.378686</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.519821</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>-0.336568</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>-0.564665</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.391949</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>-1.350552</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.579578</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.746871</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.026783</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>0.915392</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>1.164024</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>-0.108939</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.564665</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>1.455462</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.787572</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore    Gender       Age    Tenure   Balance  NumOfProducts  \\\n",
       "4296     1.287876  0.912419  0.102810  1.378686  0.796976      -0.911583   \n",
       "4049    -0.336568  0.912419 -0.564665 -0.350204 -1.225848       0.807737   \n",
       "6011    -1.350552 -1.095988  0.579578 -1.387538  0.746871      -0.911583   \n",
       "9355     0.915392 -1.095988  0.102810  1.032908 -1.225848      -0.911583   \n",
       "3624    -0.108939 -1.095988 -0.564665 -1.387538  1.455462      -0.911583   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  country_France  \\\n",
       "4296   0.646092       -1.030670        -0.519821        0.997204   \n",
       "4049   0.646092        0.970243        -0.391949       -1.002804   \n",
       "6011   0.646092        0.970243        -1.026783       -1.002804   \n",
       "9355   0.646092       -1.030670         1.164024       -1.002804   \n",
       "3624  -1.547768        0.970243         0.787572        0.997204   \n",
       "\n",
       "      country_Germany  country_Spain  Class/Exited  \n",
       "4296        -0.578736      -0.573809             0  \n",
       "4049        -0.578736       1.742740             0  \n",
       "6011         1.727904      -0.573809             1  \n",
       "9355        -0.578736       1.742740             0  \n",
       "3624        -0.578736      -0.573809             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make our training set and test set data out of our data set\n",
    "We use 8500 data to train and 1500 data for testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>Class/Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>1.287876</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>1.378686</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.519821</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>-0.336568</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>-0.564665</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.391949</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>-1.350552</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.579578</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.746871</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.026783</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>0.915392</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>1.164024</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>-0.108939</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.564665</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>1.455462</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.787572</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>-1.422980</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>3.154125</td>\n",
       "      <td>-0.695982</td>\n",
       "      <td>0.359282</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.327591</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1.008513</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-1.136786</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>0.232168</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.549010</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9074</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.480423</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>-0.119286</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-1.041433</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>0.342256</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>1.358647</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>-1.867891</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>-0.850726</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>0.783712</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.552906</td>\n",
       "      <td>-1.002804</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore    Gender       Age    Tenure   Balance  NumOfProducts  \\\n",
       "4296     1.287876  0.912419  0.102810  1.378686  0.796976      -0.911583   \n",
       "4049    -0.336568  0.912419 -0.564665 -0.350204 -1.225848       0.807737   \n",
       "6011    -1.350552 -1.095988  0.579578 -1.387538  0.746871      -0.911583   \n",
       "9355     0.915392 -1.095988  0.102810  1.032908 -1.225848      -0.911583   \n",
       "3624    -0.108939 -1.095988 -0.564665 -1.387538  1.455462      -0.911583   \n",
       "...           ...       ...       ...       ...       ...            ...   \n",
       "3311    -1.422980  0.912419  3.154125 -0.695982  0.359282      -0.911583   \n",
       "1310     1.008513 -1.095988 -1.136786 -1.041760  0.232168      -0.911583   \n",
       "9074    -0.440036 -1.095988  0.198164 -0.004426 -1.225848       0.807737   \n",
       "1860    -0.119286 -1.095988 -1.041433  1.032908  0.342256      -0.911583   \n",
       "6679    -1.867891  0.912419 -0.850726 -0.350204  0.783712      -0.911583   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  country_France  \\\n",
       "4296   0.646092       -1.030670        -0.519821        0.997204   \n",
       "4049   0.646092        0.970243        -0.391949       -1.002804   \n",
       "6011   0.646092        0.970243        -1.026783       -1.002804   \n",
       "9355   0.646092       -1.030670         1.164024       -1.002804   \n",
       "3624  -1.547768        0.970243         0.787572        0.997204   \n",
       "...         ...             ...              ...             ...   \n",
       "3311   0.646092        0.970243        -0.327591       -1.002804   \n",
       "1310   0.646092        0.970243         0.549010       -1.002804   \n",
       "9074   0.646092        0.970243        -0.480423        0.997204   \n",
       "1860   0.646092        0.970243         1.358647       -1.002804   \n",
       "6679   0.646092       -1.030670        -0.552906       -1.002804   \n",
       "\n",
       "      country_Germany  country_Spain  Class/Exited  \n",
       "4296        -0.578736      -0.573809             0  \n",
       "4049        -0.578736       1.742740             0  \n",
       "6011         1.727904      -0.573809             1  \n",
       "9355        -0.578736       1.742740             0  \n",
       "3624        -0.578736      -0.573809             0  \n",
       "...               ...            ...           ...  \n",
       "3311        -0.578736       1.742740             0  \n",
       "1310         1.727904      -0.573809             0  \n",
       "9074        -0.578736      -0.573809             0  \n",
       "1860        -0.578736       1.742740             0  \n",
       "6679        -0.578736       1.742740             0  \n",
       "\n",
       "[8500 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size =8500#here\n",
    "train_set=df[0:train_size]\n",
    "test_set=df[train_size:]\n",
    "train_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate input and label in train set and test set then convert them to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_input = train_set.iloc[:, :12]\n",
    "train_label = train_set.iloc[:, 12:]\n",
    "\n",
    "test_input = test_set.iloc[:, :12]\n",
    "test_label = test_set.iloc[:, 12:]\n",
    "\n",
    "\n",
    "\n",
    "train_input=train_input.to_numpy()\n",
    "train_label=train_label.to_numpy()\n",
    "\n",
    "\n",
    "test_input=test_input.to_numpy()\n",
    "test_label=test_label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOOHOO and now lets create out model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we shall create our model by detecting the best learning rate (alpha), epoch number and number of nodes in each layer as number of layers. we use random library for random testing these hyper parameters.\n",
    "after creating out hidden layers we will add 2 more layers , a layer with 2 nodes (because our model shall defect 2 classes)\n",
    "and a softmax layer.\n",
    "after testing optimizers that provided by tensorflow , we realized that adam optimizer is the best one that is compatible with our model and data set.\n",
    "the acceptable testing accuracy is 84% and training accuracy is 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_genarator(number_layer,array_number_neron):\n",
    "    model = tf.keras.Sequential([])\n",
    "    for i in range(number_layer):\n",
    "        model.add(tf.keras.Sequential([tf.keras.layers.Dense(array_number_neron[i], activation='relu')]))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 20, 40, 40, 20, 20, 50, 10]\n",
      "rate:\n",
      "1e-13\n",
      "steps:\n",
      "100\n",
      "Train on 8500 samples\n",
      "Epoch 1/100\n",
      "8500/8500 [==============================] - 1s 110us/sample - loss: 0.5191 - accuracy: 0.7982\n",
      "Epoch 2/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4800 - accuracy: 0.8291\n",
      "Epoch 3/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4724 - accuracy: 0.8384\n",
      "Epoch 4/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4698 - accuracy: 0.8388\n",
      "Epoch 5/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4683 - accuracy: 0.8404\n",
      "Epoch 6/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4577 - accuracy: 0.8512\n",
      "Epoch 7/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4490 - accuracy: 0.8612\n",
      "Epoch 8/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4455 - accuracy: 0.8647\n",
      "Epoch 9/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4426 - accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4408 - accuracy: 0.8699\n",
      "Epoch 11/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4407 - accuracy: 0.8687\n",
      "Epoch 12/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4386 - accuracy: 0.8718\n",
      "Epoch 13/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4391 - accuracy: 0.8711\n",
      "Epoch 14/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4417 - accuracy: 0.8694\n",
      "Epoch 15/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4390 - accuracy: 0.8713\n",
      "Epoch 16/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4388 - accuracy: 0.8724\n",
      "Epoch 17/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4386 - accuracy: 0.8724\n",
      "Epoch 18/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4370 - accuracy: 0.8752\n",
      "Epoch 19/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4346 - accuracy: 0.8751\n",
      "Epoch 20/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4351 - accuracy: 0.8751\n",
      "Epoch 21/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4372 - accuracy: 0.8745\n",
      "Epoch 22/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4349 - accuracy: 0.8768\n",
      "Epoch 23/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4319 - accuracy: 0.8786\n",
      "Epoch 24/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4323 - accuracy: 0.8778\n",
      "Epoch 25/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4301 - accuracy: 0.8812\n",
      "Epoch 26/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4297 - accuracy: 0.8822\n",
      "Epoch 27/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4341 - accuracy: 0.8771\n",
      "Epoch 28/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4326 - accuracy: 0.8788\n",
      "Epoch 29/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4302 - accuracy: 0.8818\n",
      "Epoch 30/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4300 - accuracy: 0.8816s - loss: 0.4257 - accuracy\n",
      "Epoch 31/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4287 - accuracy: 0.8832\n",
      "Epoch 32/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4302 - accuracy: 0.8813\n",
      "Epoch 33/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4284 - accuracy: 0.8833\n",
      "Epoch 34/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4260 - accuracy: 0.8859\n",
      "Epoch 35/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4296 - accuracy: 0.8816\n",
      "Epoch 36/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4288 - accuracy: 0.8818\n",
      "Epoch 37/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4282 - accuracy: 0.8841\n",
      "Epoch 38/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4296 - accuracy: 0.8819\n",
      "Epoch 39/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4278 - accuracy: 0.8847\n",
      "Epoch 40/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4271 - accuracy: 0.8845\n",
      "Epoch 41/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4281 - accuracy: 0.8827\n",
      "Epoch 42/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4235 - accuracy: 0.8881\n",
      "Epoch 43/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4228 - accuracy: 0.8881\n",
      "Epoch 44/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4239 - accuracy: 0.8884\n",
      "Epoch 45/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4256 - accuracy: 0.8856\n",
      "Epoch 46/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4227 - accuracy: 0.8887\n",
      "Epoch 47/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4222 - accuracy: 0.8908\n",
      "Epoch 48/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4293 - accuracy: 0.8822\n",
      "Epoch 49/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4224 - accuracy: 0.8896\n",
      "Epoch 50/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4265 - accuracy: 0.8853\n",
      "Epoch 51/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4237 - accuracy: 0.8888\n",
      "Epoch 52/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4244 - accuracy: 0.8886\n",
      "Epoch 53/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4269 - accuracy: 0.8854\n",
      "Epoch 54/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4223 - accuracy: 0.8895s - loss: 0.4228 - accu\n",
      "Epoch 55/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4220 - accuracy: 0.8902\n",
      "Epoch 56/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4193 - accuracy: 0.8933\n",
      "Epoch 57/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4224 - accuracy: 0.8902\n",
      "Epoch 58/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4213 - accuracy: 0.8912\n",
      "Epoch 59/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4196 - accuracy: 0.8931\n",
      "Epoch 60/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4205 - accuracy: 0.8922\n",
      "Epoch 61/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4237 - accuracy: 0.8891\n",
      "Epoch 62/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4249 - accuracy: 0.8875\n",
      "Epoch 63/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4202 - accuracy: 0.8925\n",
      "Epoch 64/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4210 - accuracy: 0.8916\n",
      "Epoch 65/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4206 - accuracy: 0.8915\n",
      "Epoch 66/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4195 - accuracy: 0.8931\n",
      "Epoch 67/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4200 - accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4187 - accuracy: 0.8942\n",
      "Epoch 69/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4204 - accuracy: 0.8913\n",
      "Epoch 70/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4167 - accuracy: 0.8958\n",
      "Epoch 71/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4188 - accuracy: 0.8940\n",
      "Epoch 72/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4194 - accuracy: 0.8933\n",
      "Epoch 73/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4236 - accuracy: 0.8891\n",
      "Epoch 74/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4232 - accuracy: 0.8895\n",
      "Epoch 75/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4198 - accuracy: 0.8927\n",
      "Epoch 76/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4192 - accuracy: 0.8929\n",
      "Epoch 77/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4190 - accuracy: 0.8933\n",
      "Epoch 78/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4161 - accuracy: 0.8962\n",
      "Epoch 79/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4201 - accuracy: 0.8915\n",
      "Epoch 80/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4182 - accuracy: 0.8944\n",
      "Epoch 81/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4182 - accuracy: 0.8947\n",
      "Epoch 82/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4208 - accuracy: 0.8916\n",
      "Epoch 83/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4200 - accuracy: 0.8907\n",
      "Epoch 84/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4193 - accuracy: 0.8931\n",
      "Epoch 85/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4219 - accuracy: 0.8906\n",
      "Epoch 86/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4246 - accuracy: 0.8868\n",
      "Epoch 87/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4205 - accuracy: 0.8913\n",
      "Epoch 88/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4166 - accuracy: 0.8967\n",
      "Epoch 89/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4221 - accuracy: 0.8906\n",
      "Epoch 90/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4342 - accuracy: 0.8787\n",
      "Epoch 91/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4272 - accuracy: 0.8855\n",
      "Epoch 92/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4239 - accuracy: 0.8889\n",
      "Epoch 93/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4203 - accuracy: 0.8919\n",
      "Epoch 94/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4162 - accuracy: 0.8959\n",
      "Epoch 95/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4166 - accuracy: 0.8965\n",
      "Epoch 96/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4214 - accuracy: 0.8904\n",
      "Epoch 97/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4176 - accuracy: 0.8956\n",
      "Epoch 98/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4235 - accuracy: 0.8892\n",
      "Epoch 99/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4193 - accuracy: 0.8932\n",
      "Epoch 100/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4175 - accuracy: 0.8952\n",
      "8500/8500 [==============================] - 0s 33us/sample - loss: 0.4175 - accuracy: 0.8939\n",
      "train_acc:0.89388233\n",
      "1500/1500 - 0s - loss: 0.4739 - accuracy: 0.8360\n",
      "test_acc:0.836\n",
      "[50, 30, 50, 50, 30, 40, 40, 10]\n",
      "rate:\n",
      "1e-06\n",
      "steps:\n",
      "100\n",
      "Train on 8500 samples\n",
      "Epoch 1/100\n",
      "8500/8500 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.79 - 1s 94us/sample - loss: 0.5176 - accuracy: 0.7976\n",
      "Epoch 2/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4829 - accuracy: 0.8221\n",
      "Epoch 3/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4702 - accuracy: 0.8375\n",
      "Epoch 4/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4656 - accuracy: 0.8440\n",
      "Epoch 5/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4592 - accuracy: 0.8496\n",
      "Epoch 6/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4495 - accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4469 - accuracy: 0.8629\n",
      "Epoch 8/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4438 - accuracy: 0.8661\n",
      "Epoch 9/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4432 - accuracy: 0.8647\n",
      "Epoch 10/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4408 - accuracy: 0.8687\n",
      "Epoch 11/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4409 - accuracy: 0.8706\n",
      "Epoch 12/100\n",
      "8500/8500 [==============================] - 0s 48us/sample - loss: 0.4392 - accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "8500/8500 [==============================] - 1s 63us/sample - loss: 0.4381 - accuracy: 0.8718\n",
      "Epoch 14/100\n",
      "8500/8500 [==============================] - 0s 53us/sample - loss: 0.4353 - accuracy: 0.8756\n",
      "Epoch 15/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4351 - accuracy: 0.8748\n",
      "Epoch 16/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4356 - accuracy: 0.8764\n",
      "Epoch 17/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4334 - accuracy: 0.8768\n",
      "Epoch 18/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4308 - accuracy: 0.8794\n",
      "Epoch 19/100\n",
      "8500/8500 [==============================] - 0s 47us/sample - loss: 0.4318 - accuracy: 0.8805\n",
      "Epoch 20/100\n",
      "8500/8500 [==============================] - 0s 48us/sample - loss: 0.4338 - accuracy: 0.8766\n",
      "Epoch 21/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4316 - accuracy: 0.8801\n",
      "Epoch 22/100\n",
      "8500/8500 [==============================] - 0s 47us/sample - loss: 0.4322 - accuracy: 0.8776\n",
      "Epoch 23/100\n",
      "8500/8500 [==============================] - 0s 48us/sample - loss: 0.4298 - accuracy: 0.8804s - loss: 0.4264 - ac\n",
      "Epoch 24/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4289 - accuracy: 0.8818\n",
      "Epoch 25/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4261 - accuracy: 0.8851\n",
      "Epoch 26/100\n",
      "8500/8500 [==============================] - 0s 46us/sample - loss: 0.4283 - accuracy: 0.8822\n",
      "Epoch 27/100\n",
      "8500/8500 [==============================] - 0s 47us/sample - loss: 0.4272 - accuracy: 0.8836\n",
      "Epoch 28/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4264 - accuracy: 0.8845s - loss: 0.4228 - ac\n",
      "Epoch 29/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4243 - accuracy: 0.8862\n",
      "Epoch 30/100\n",
      "8500/8500 [==============================] - 0s 47us/sample - loss: 0.4302 - accuracy: 0.8822\n",
      "Epoch 31/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4284 - accuracy: 0.8825\n",
      "Epoch 32/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4235 - accuracy: 0.8891\n",
      "Epoch 33/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4251 - accuracy: 0.8868\n",
      "Epoch 34/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4300 - accuracy: 0.8815\n",
      "Epoch 35/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4247 - accuracy: 0.8868\n",
      "Epoch 36/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4232 - accuracy: 0.8884\n",
      "Epoch 37/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4235 - accuracy: 0.8887\n",
      "Epoch 38/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4246 - accuracy: 0.8875\n",
      "Epoch 39/100\n",
      "8500/8500 [==============================] - 0s 45us/sample - loss: 0.4227 - accuracy: 0.8880\n",
      "Epoch 40/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4217 - accuracy: 0.8876s - loss: 0.4219 - accuracy: 0.88\n",
      "Epoch 41/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4237 - accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4268 - accuracy: 0.8851\n",
      "Epoch 43/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4234 - accuracy: 0.8887\n",
      "Epoch 44/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4213 - accuracy: 0.8900\n",
      "Epoch 45/100\n",
      "8500/8500 [==============================] - 0s 47us/sample - loss: 0.4203 - accuracy: 0.8926\n",
      "Epoch 46/100\n",
      "8500/8500 [==============================] - 0s 50us/sample - loss: 0.4246 - accuracy: 0.8873\n",
      "Epoch 47/100\n",
      "8500/8500 [==============================] - 0s 48us/sample - loss: 0.4263 - accuracy: 0.8858\n",
      "Epoch 48/100\n",
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4205 - accuracy: 0.8916\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500/8500 [==============================] - 0s 41us/sample - loss: 0.4177 - accuracy: 0.8947\n",
      "Epoch 50/100\n",
      "8500/8500 [==============================] - 0s 40us/sample - loss: 0.4200 - accuracy: 0.8918\n",
      "Epoch 51/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4184 - accuracy: 0.8933s - loss: 0.4218 - accuracy\n",
      "Epoch 52/100\n",
      "8500/8500 [==============================] - 0s 44us/sample - loss: 0.4242 - accuracy: 0.8880\n",
      "Epoch 53/100\n",
      "8500/8500 [==============================] - 0s 42us/sample - loss: 0.4264 - accuracy: 0.8854\n",
      "Epoch 54/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4197 - accuracy: 0.8922\n",
      "Epoch 55/100\n",
      "8500/8500 [==============================] - 0s 43us/sample - loss: 0.4218 - accuracy: 0.8911\n",
      "Epoch 56/100\n",
      "2144/8500 [======>.......................] - ETA: 0s - loss: 0.4233 - accuracy: 0.8876"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-18ba88d5e813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0marray_of_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marray_of_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_acc:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a=0\n",
    "\n",
    "\n",
    "train_input_copy=train_input\n",
    "train_label_copy=train_label\n",
    "\n",
    "\n",
    "test_input_copy=test_input\n",
    "test_label_copy=test_label\n",
    "const_model=tf.keras.Sequential([tf.keras.layers.Dense(2),\n",
    "    tf.keras.layers.Softmax()])\n",
    "array_of_models=[]\n",
    "inter=0\n",
    "while(1):\n",
    "    \n",
    "    train_input=train_input_copy\n",
    "    train_label=train_label_copy\n",
    "    \n",
    "    test_input=test_input_copy\n",
    "    test_label=test_label_copy\n",
    "    \n",
    "    number_epoch=10**(randrange(2)+2)\n",
    "    h=randrange(15)\n",
    "    h=h-14\n",
    "    learning_rate=10**h\n",
    "    \n",
    "    number_layer=randrange(5)+5\n",
    "    layer_neron=[]\n",
    "    for i in range(number_layer):\n",
    "        layer_neron.append((randrange(5)+1)*10)\n",
    "    print(layer_neron)\n",
    "    \n",
    "    x=Model_genarator(number_layer,layer_neron)\n",
    "    x.add(const_model)\n",
    "    array_of_models.append(x)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"rate:\")\n",
    "    print(learning_rate)\n",
    "    print(\"steps:\")\n",
    "    print(number_epoch)\n",
    "\n",
    "#     opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "#     opt=tf.keras.optimizers.Adam(\n",
    "#     learning_rate=learning_rate, amsgrad=False,\n",
    "#     name='Adam'\n",
    "#     )\n",
    "    array_of_models[inter].compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()],)\n",
    "\n",
    "\n",
    "    array_of_models[inter].fit(train_input,train_label, epochs=number_epoch)\n",
    "    a=array_of_models[inter].evaluate(train_input,train_label)[1]\n",
    "    print('train_acc:'+str(a))\n",
    "    test_loss, test_acc = array_of_models[inter].evaluate(test_input,  test_label, verbose=2)\n",
    "    print('test_acc:'+str(test_acc))\n",
    "    inter=inter+1\n",
    "    if(test_acc>0.84 and a>0.9):\n",
    "        print(\"!!!finished!!!\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "# weights = model.get_weights()\n",
    "# print(weights[0][0])\n",
    "# model.fit(train_input,train_label, epochs=10)\n",
    "# weights1 = model.get_weights()\n",
    "# print(weights[0][0]-weights1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wsave = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randrange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
